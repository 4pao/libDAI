TODO:

- Improve documentation.

- Adapt http://www.boost.org/development/requirements.html#Design_and_Programming

- Use "gcc -MM" to generate dependencies for targets.
  Maybe even better: switch to cmake (see http://lwn.net/Articles/188693/)
  cross-platform build system.


OPTIMIZATION:

- BipartiteGraph::isConnected should be optimized using boost::graph

- Replace VarSets by smallSet<size_t> where appropriate, in order to minimize the use of findVar().

- A DAIAlg<T> should not inherit from a FactorGraph/RegionGraph, but should
  store a reference to it.  This prevents needless copying of (possibly large)
  data structures. Disadvantage: the caller must not change the data structure
  between calls. (Maybe a smart_ptr would help here?)
  Also, general marginalization functions now copy a complete object. Instead, it
  would make more sense that they construct a new object without copying the
  FactorGraph. Or they can simply be made methods of the general InfAlg class.


IDEAS WORTH EXPLORING:

- Use a PropertySet as output of a DAIAlg, instead of functions like maxDiff and Iterations().

- Cache second-order neighborhoods (delta's) in BipGraph?

- If you ever do a rewrite, make sure that the graphical properties are not
  entangled with the probabilistic properties. E.g., a factor graph really
  should be represented as a bipartite graph, with a separate array of variable
  labels and dimensions, and a seperate array of (pointers to) factor tables. In
  this way, each factor could be implemented differently, e.g., we could have
  some sparse factors, some noisy-OR factors, some dense factors, some arbitrary
  precision factors, etc. Or we could make more use of templates to have a more
  generic factor graph. 

- Use Boost::uBLAS framework to deal with matrices, especially, with
  2D sparse matrices. 
  See http://www.boost.org/libs/numeric/ublas/doc/matrix_sparse.htm
  and tests/errorbounds/errorbounds3

- Introduce naming scheme:
  all Vars and VarSets should be named v_..., e.g. v_i instead of i
  all Factors should be named f_..., e.g. f_I instead of I
  all indices should be named _..., e.g. _k instead of k
  all iterators should be named i_, e.g. i_i is an iterator to i
  all const_iterators should be named ci_, e.g. ci_i is an iterator to i

- Define a better fileformat for .fg files (maybe using XML)?

- Alternative implementation of undo factor changes: the only things that have to be
  undone are setting a factor to all ones and setting a factor to a Kronecker delta. This
  could also be implemented in the factor itself, which could maintain its state 
  (one/delta/full) and act accordingly.

- Think about the RegionGraph::fac2OR variable: a better implementation of this feature is
  probably possible.

- Optimize GBP with precalculated indices.

- Optimize all indices as follows: keep a cache of all indices that have been
  computed (use a hash). Then, instead of computing on the fly, use the precomputed ones.

- Variable elimination should be implemented generically using a function
  object that tells you which variable to delete.

- Improve general support for graphs and trees.

- Add support for sparse potentials.

- Optimize BP_SEQMAX (it should use a better data structure than a vector for the residuals).


BAD IDEAS:

- A FactorGraph and a RegionGraph are often equipped with
  additional properties for nodes and edges. The code to initialize those
  is often quite similar; maybe this can be abstracted to classes
  like ExtFactorGraph and ExtRegionGraph (Ext stands for Extended), e.g.
  template <typename NodeProperties, typename EdgeProperties>
  class ExtFactorGraph : public FactorGraph {
	public:
		std::vector<NodeProperties>               nodeProps;
		std::vector<std::vector<EdgeProperties> > edgeProps;
	// blabla
  }
  A disadvantage of this approach may be worse cachability.
  A problem is if there are nog properties for nodes (type 1), nodes (type 2)
  or edges. Maybe this can be solved using specializations, or using variadac
  template arguments or something similar?
  Idea: you could define a "class Empty {}", and add some code that checks for
  the typeid, comparing it with Empty, and doing something special in that case 
  (e.g., not allocating memory).
  The main disadvantage of this approach seems to be that it leads to even more
  entanglement.

- Instead of polymorphism by inheritance, use polymorphism by template
  parameterization. For example, the real reason you introduced the complicated
  inheritance scheme was for functions like
      Factor calcMarginal( const InferenceAlgorithm & obj, const VarSet & ns, bool reInit );
  Now instead, you could use a template function:
      template<typename InferenceAlgorithm>
      Factor calcMarginal( const InferenceAlgorithm &obj, const VarSet &ns, bool reInit );
  This would assume that InferenceAlgorithm supports certain methods, like
  clone(), grm(), ......  Ideally, you would use concepts to define different
  classes of inference algorithms with different capabilities, for example the
  ability to calculate logZ, the ability to calculate marginals, the ability to
  calculate bounds, the ability to calculate MAP states, etcetera. Then, use
  traits classes in order to be able to query the capabilities of the model. For
  example, you would be able to query whether the inference algorithm supports
  calculation of logZ.  Unfortunately, this is compile-time polymorphism, whereas
  tests/test needs runtime polymorphism.
